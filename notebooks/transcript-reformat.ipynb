{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a4dbf15-2e57-4e55-aae1-683c404e9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"OPENAI_API_KEY isn't set; set it in your environment (and restart the noteboook) or set it below...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ec896e7-68ca-415d-8fce-109be3d89605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you didn't set the key...\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),  # This is the default and can be omitted\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "979cda92-4246-451d-bd48-4374e6715a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ianbicking/src/podcast-tools/transcripts ['episode-4-18.txt', 'episode-4-17.txt', 'episode-4-16.txt', 'episode-4-14.txt', 'episode-4-15.txt']\n"
     ]
    }
   ],
   "source": [
    "transcript_directory = os.path.abspath(\"../transcripts\")\n",
    "transcript_filenames = os.listdir(transcript_directory)\n",
    "print(transcript_directory, transcript_filenames)\n",
    "link_data = json.loads(open(\"../links.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abf15265-5adf-4be8-a0a0-736c6edaa645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode-4-18.txt: 50455 bytes, 9270 words\n",
      "episode-4-17.txt: 41242 bytes, 7529 words\n",
      "episode-4-16.txt: 36730 bytes, 6435 words\n",
      "episode-4-14.txt: 55325 bytes, 10177 words\n",
      "episode-4-15.txt: 45859 bytes, 8243 words\n"
     ]
    }
   ],
   "source": [
    "transcripts = {}\n",
    "links = {}\n",
    "for fn in transcript_filenames:\n",
    "    transcripts[fn] = open(os.path.join(transcript_directory, fn)).read()\n",
    "    links[fn] = [item for item in link_data if item[\"name\"] == fn][0][\"url\"]\n",
    "for key, value in transcripts.items():\n",
    "    bytes = len(value)\n",
    "    words = len(value.split())\n",
    "    print(f\"{key}: {bytes} bytes, {words} words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f92c5afb-d37c-4f25-ba7c-1c7adc59b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_prompt = \"\"\"\n",
    "You are given a raw podcast transcript. **Transform it into Markdown** by following these rules:\n",
    "\n",
    "1. **Remove or Merge Filler Words**\n",
    "   - Delete common fillers and repeated words like \"um,\" \"uh,\" \"you know,\" \"like,\" \"right?,\" etc. unless needed for meaning.\n",
    "   - Merge short interjections (e.g., “Yeah,” “Sure”) into the nearest sentence if they don’t add standalone value.\n",
    "\n",
    "   **Examples**:\n",
    "   ```\n",
    "   INPUT:\n",
    "   [00:02:10] Justin Grammens: Um, I'm not sure, but, like, we can definitely talk about XR, right?\n",
    "\n",
    "   OUTPUT:\n",
    "   [00:02:10] Justin Grammens: I'm not sure, but we can definitely talk about [XR (extended reality)](https://www.google.com/search?q=XR+extended+reality).\n",
    "   ```\n",
    "\n",
    "   ```\n",
    "   INPUT:\n",
    "   [00:03:00] Nick Roseth: Yeah. Yeah. So, I was thinking, um, that it might be easier just to, you know, do it ourselves.\n",
    "\n",
    "   OUTPUT:\n",
    "   [00:03:00] Nick Roseth: I was thinking it might be easier to do it ourselves.\n",
    "   ```\n",
    "\n",
    "2. **Link References and Acronyms**\n",
    "   - Use Markdown links for references (books, studies, organizations) with a placeholder Google search URL.\n",
    "   - For first mention of an acronym, include an expansion in parentheses, then link it.\n",
    "\n",
    "   **Examples**:\n",
    "   ```\n",
    "   INPUT:\n",
    "   [00:04:05] Justin Grammens: There's a PWC study about adoption.\n",
    "\n",
    "   OUTPUT:\n",
    "   [00:04:05] Justin Grammens: There's a [PWC study](https://www.google.com/search?q=PWC+study+about+adoption) about adoption.\n",
    "   ```\n",
    "\n",
    "   ```\n",
    "   INPUT:\n",
    "   [00:04:22] Nick Roseth: We used RAG or retrieval augmented generation.\n",
    "\n",
    "   OUTPUT:\n",
    "   [00:04:22] Nick Roseth: We used [RAG (retrieval augmented generation)](https://www.google.com/search?q=RAG+retrieval+augmented+generation).\n",
    "   ```\n",
    "\n",
    "3. **Create Lists Where Appropriate**\n",
    "   - When speakers enumerate items (e.g. “first, second, third”), convert them into a Markdown list.\n",
    "\n",
    "   **Example**:\n",
    "   ```\n",
    "   INPUT:\n",
    "   [00:05:10] Justin Grammens: We have three steps. One, gather data. Two, build a model. Three, evaluate results.\n",
    "\n",
    "   OUTPUT:\n",
    "   [00:05:10] Justin Grammens:\n",
    "   We have three steps:\n",
    "   1. Gather data\n",
    "   2. Build a model\n",
    "   3. Evaluate results\n",
    "   ```\n",
    "\n",
    "4. **Intro and Outro in Blockquotes**\n",
    "   - If you detect content that introduces or concludes the show (like sponsor ads, host signoffs), enclose that text in blockquotes (`>`). Each line should start with `>`.\n",
    "\n",
    "   **Example**:\n",
    "   ```\n",
    "   INPUT:\n",
    "   [00:00:38] AI Voice: You can visit us at AppliedAI.mn to keep up to date on events. Thanks for listening.\n",
    "\n",
    "   OUTPUT:\n",
    "   > You can visit us at AppliedAI.mn to keep up to date on events.\n",
    "   > Thanks for listening.\n",
    "   ```\n",
    "\n",
    "   Any portion of the transcript read by a \"AI Announcer\" is an intro/outro. The speaker can be removed and the text blockquoted.\n",
    "\n",
    "5. **Use Paragraph Breaks**\n",
    "   - Break large blocks of speech into paragraphs of ~3–5 sentences (or ~250 words) each.\n",
    "   - Start a new paragraph at a logical topic shift.\n",
    "\n",
    "   **Example**:\n",
    "   ```\n",
    "   INPUT:\n",
    "   [00:06:40] Nick Roseth: So I started in design years ago, focusing on print, then moved to web, then eventually found AR and VR. I realized those technologies can transform industries, from construction to healthcare, but there's slow adoption. The reality is, we need to examine human behavior and acceptance of emerging tech. It's not just about the technology. A big factor is trust.\n",
    "\n",
    "   OUTPUT:\n",
    "   [00:06:40] Nick Roseth:\n",
    "   I started in design years ago, focusing first on print, then moving into web. Eventually, I found AR and VR. I realized these technologies can transform industries, from construction to healthcare.\n",
    "\n",
    "   There's still slow adoption, because we have to look at human behavior and acceptance of emerging tech. It's not just about the technology itself. A big factor is trust.\n",
    "   ```\n",
    "\n",
    "6. **No Headings**\n",
    "   - Do not insert or create headings (e.g., `# Introduction`, `## Overview`, etc.).\n",
    "   - Stick to paragraphs, blockquotes, links, and lists only.\n",
    "\n",
    "7. **Keep Speaker Labels on One Line**\n",
    "   - Format each speaker turn as `\"[timestamp] Speaker: text\"`.  (Omit the timestamp if not given)\n",
    "   - Use the exact speaker name from the transcript (no custom headings).\n",
    "   - **Example**:\n",
    "     ```\n",
    "     [00:07:30] Justin Grammens:\n",
    "     Let's talk about data privacy next.\n",
    "\n",
    "     becomes\n",
    "\n",
    "     [00:07:30] Justin Grammens: Let's talk about data privacy next.\n",
    "     ```\n",
    "\n",
    "8. **Timestamps**\n",
    "   - Retain original timestamps in the format `[00:00]`.\n",
    "   - Keep them at the start of each speaker line, directly before the speaker’s name.\n",
    "   - Do not remove, alter, or relocate them.\n",
    "\n",
    "---\n",
    "\n",
    "**Return the cleaned transcript in Markdown** following these rules. Remember:\n",
    "\n",
    "- **Remove filler words**\n",
    "- **Link references/acronyms**\n",
    "- **Create lists** (if items are enumerated)\n",
    "- **Blockquote** intro/outro text\n",
    "- **Insert paragraph breaks** for readability\n",
    "- **No headings**\n",
    "- **Speaker label on one line**\n",
    "- **Keep timestamps**\n",
    "\n",
    "Use these **expanded examples** as a guide:\n",
    "\n",
    "```\n",
    "INPUT:\n",
    "[00:10:05] Justin Grammens: Um, so I think we have, like, a few new developments. One, the Apple Vision Pro. Two, new updates in ChatGPT. Three, expansions in RAG, right?\n",
    "\n",
    "OUTPUT:\n",
    "[00:10:05] Justin Grammens:\n",
    "I think we have a few new developments:\n",
    "1. The [Apple Vision Pro](https://www.google.com/search?q=Apple+Vision+Pro)\n",
    "2. New updates in [ChatGPT](https://www.google.com/search?q=ChatGPT)\n",
    "3. Expansions in [RAG (retrieval augmented generation)](https://www.google.com/search?q=RAG+retrieval+augmented+generation)\n",
    "```\n",
    "\n",
    "```\n",
    "INPUT:\n",
    "[00:12:45] AI Voice: Thank you for listening to the show. Please visit us at OurSite.com.\n",
    "\n",
    "OUTPUT:\n",
    "> Thank you for listening to the show.\n",
    "> Please visit us at [OurSite.com](https://www.google.com/search?q=OurSite.com)\n",
    "```\n",
    "\n",
    "```\n",
    "INPUT:\n",
    "[00:15:33] Nick Roseth: Right, yeah, so, um, I guess XR is basically extended reality, so, yeah, I guess that's it.\n",
    "\n",
    "OUTPUT:\n",
    "[00:15:33] Nick Roseth: XR is basically [extended reality](https://www.google.com/search?q=extended+reality).\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2525ad75-c971-4be2-8665-26eef7e6b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_transcript(text):\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": transcript_prompt},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ]\n",
    "    )\n",
    "    return resp.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbba152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_quotes(text):\n",
    "    text = text.strip()\n",
    "    if text.startswith(\"```\"):\n",
    "        text = text.split(\"\\n\", 1)[1]\n",
    "    if text.endswith(\"```\"):\n",
    "        text = text.rsplit(\"\\n\", 1)[0]\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3b15300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:00] David Wynn: The mental model I like to give people is imagine a guy in a bar overheard 10,000 hours of two people next to him talking about motorcycles. He has never seen, driven, heard, or felt one. When you ask him a question about motorcycles, he’ll probably give you the right answer. Occasionally, he might compliment how your torque smells. It's not his fault. He's just trying to piece together everything he could possibly know from what he's heard. He's not really thinking it through. I think that model is key for people to grasp. As a result, summarizing—where I'm trusting someone to come up with the important stuff I need to know—feels a bit suspicious to me. If we called it shortening, that’d be different. Summarizing, I’m a little wary of.\n",
      "\n",
      "[00:00:48] AI Announcer: Welcome to the Conversations on Applied AI podcast, where Justin Grammens and the team at Emerging Technologies North talk with experts in the fields of artificial intelligence and deep learning. In each episode, we cut through the hype and dive into how these technologies are being applied to real-world problems today. We hope you find this episode educational and applicable to your industry. Connect with us to learn more about our organization at [AppliedAI.mn](https://www.google.com/search?q=AppliedAI.mn). Enjoy.\n",
      "\n",
      "[00:01:19] Justin Grammens: Welcome, everyone, to the Conversations on Applied AI podcast. I'm your host, Justin Grammens, and our guest today is David Wynn. David is the Principal Solution Architect at EdgeDelta and an enthusiast for all things technology. \n",
      "\n",
      "With a career spanning 15 years, including a pivotal role at Google Cloud for Games, David has cultivated a deep understanding of technical sales, solution architecture, and the transformative power of cloud services in the gaming industry and beyond. His unique perspective challenges the overreliance on AI, advocating for a balanced approach that leverages human ingenuity alongside technological advancements, especially in areas like observability.\n",
      "\n",
      "When he's not steering innovation, David revels in the vibrant geek culture of Atlanta and is a regular at DragonCon, the largest multimedia popular culture convention focusing on science fiction and fantasy. His diverse interests span from technology to philosophy. I’m sure we’re going to have an awesome conversation today about AI and its applications. Thank you so much for being on the program.\n",
      "\n",
      "[00:02:11] David Wynn: Absolutely, Justin. Pleasure to be here.\n",
      "\n",
      "[00:02:13] Justin Grammens: Awesome. I touched on some of your background at Google and your current role. I'm curious, how did you get into technology? Were you always fascinated with programming?\n",
      "\n",
      "[00:02:31] David Wynn: I grew up in Greenville, South Carolina, which is not a technical hub in the U.S. My only teacher, Miss Harmon, was my computer science teacher throughout high school. That was just enough to spark my interest, but I went to college for economics instead. I had the wrong impression about what it meant to be a programmer, so I thought I’d do something else.\n",
      "\n",
      "After college, I ended up spending time at UPS during the 2008 crash, where a PhD and I worked on econometrics to improve forecasting. My role involved a lot of VBA code to make Excel work for 250 time series data sets, which is where I started developing practical skills. \n",
      "\n",
      "Later, I moved to California for a relationship, and at the Stanford career fair, I found a lot of technology opportunities. I ended up doing post-sales implementation middleware, which was a form of ETL. I built scalable data pipelines for law firms and transitioned into observability at Sumo Logic. Eventually, I joined Google Cloud when it was small, around 70 sales engineers globally, which was a rapid learning experience for cloud technologies. Now, I'm back in observability at Edge Delta.\n",
      "\n",
      "[00:05:42] Justin Grammens: Great journey! For our audience, could you define what observability is?\n",
      "\n",
      "[00:05:51] David Wynn: Depending on how good your Googling or using GPT is, observability can be defined simply as logs, metrics, and traces. Essentially, an application generates data about itself to show how well it's running. Collecting and displaying that information is observability.\n",
      "\n",
      "A broader way to define it is the process of ensuring that what you’re doing is operating as expected. This understanding goes beyond any specific metric, allowing for flexibility in approach. The observability space is transitioning because our data has become enormous, reaching hundreds of terabytes to petabytes generated daily.\n",
      "\n",
      "When running applications on multiple machines, observability software pulls all that data together to find what’s important. However, scalability has become an issue as the volume increases.\n",
      "\n",
      "[00:07:24] Justin Grammens: I've worked in the Internet of Things and sensors for over 15 years. At some point, processing becomes overwhelming, and I turned to machine learning and deep learning to filter through the noise. Can you discuss AI's role in observability?\n",
      "\n",
      "[00:07:54] David Wynn: There’s a group of people very hopeful about AI, believing that if we throw all our data into it, it will find solutions. On the other hand, we know that errors and crashes are bad, and we generally understand the data we have. For example, at Edge Delta, we use a traditional machine learning model to identify statistical abnormalities. Then, we feed this information into an LLM to suggest next actions to take.\n",
      "\n",
      "This is like having a 2 a.m. crib sheet for trouble-shooting—a quick list of things to check if something goes wrong. This process can be very useful for resolving issues and getting people back to bed, especially for those new to the team.\n",
      "\n",
      "[00:09:27] Justin Grammens: It's a practical application of generative AI, particularly for junior engineers on call. They need backup when systems fail at inconvenient times.\n",
      "\n",
      "[00:09:50] David Wynn: Exactly. When debugging, you may be isolating problems across teams and encountering new challenges. This complexity can vary greatly if there’s a lack of communication around team decision-making and implementation.\n",
      "\n",
      "[00:10:21] Justin Grammens: I've talked to engineers who have difficulty deciphering logs and hardware dumps. They're looking for anomaly detection to guide them when they aren't familiar with the code or libraries.\n",
      "\n",
      "[00:10:50] David Wynn: Different approaches exist to abstract problems. Some errors may require immediate resolution, while other conditions involve deeper awareness of a broader context. Higher-level issues may relate to architecture state or model performance.\n",
      "\n",
      "LLMs can help translate command logs into actionable insights, but they struggle with new or unprecedented problems. For instance, I encountered a unique billing error at Intap—a failure in our sync service due to an unpaid account. LLMs might not provide guidance on rare errors that haven’t been encountered before, but they excel in generating ideas and constructing outlines for broader queries.\n",
      "\n",
      "[00:13:55] Justin Grammens: I agree that LLMs lack intuition when it comes to errors. They're great for specific tasks, but they struggle with nuances and unique scenarios. And while they improve efficiency in mundane tasks, they're not perfect tools for summarizing or assessing the uniqueness of issues.\n",
      "\n",
      "[00:15:47] David Wynn: Absolutely. While they can help streamline processes, their ability to resolve complex problems is limited.\n",
      "\n",
      "[00:15:59] Justin Grammens: There’s concern around AI potentially replacing jobs. What’s your view on that?\n",
      "\n",
      "[00:16:01] David Wynn: I’m generally not worried. If you try to get these technologies to perform tasks you’re concerned about, you might find challenges. For example, creating sophisticated art with AI can often lead to frustrating results. People will always seek specificity and control, which can be lost with AI.\n",
      "\n",
      "My impression is that AI is not going to completely replace roles but will enhance processes, helping eliminate inefficient tasks. AI will streamline operations, allowing people to focus on higher-level problem-solving.\n",
      "\n",
      "[00:18:53] Justin Grammens: Makes sense. Current tools enhance capabilities rather than completely displace them. People will experience increased ROI with smart tools. \n",
      "\n",
      "[00:20:26] David Wynn: Exactly! Many current AI tools become more intelligent through user interaction, enhancing daily workflows.\n",
      "\n",
      "[00:20:40] Justin Grammens: While generative AI has captured imaginations, many startups will fade away amidst the hype. Existing products will adapt and integrate AI efficiently.\n",
      "\n",
      "[00:21:44] David Wynn: Agreed! Many companies are focusing on value-driven models rather than sheer size. Innovations will improve specific applications, creating more effective and targeted solutions.\n",
      "\n",
      "[00:22:59] Justin Grammens: Observability is key to identifying and fixing system issues, as we saw with CrowdStrike recently. It highlights the need for better testing and pre-release verification of system changes.\n",
      "\n",
      "[00:27:52] David Wynn: Absolutely! If a deployment has a large blast radius, precautions should have been taken to catch potential issues. Observability measures must be effective enough to predict problems before they occur.\n",
      "\n",
      "[00:30:50] Justin Grammens: Drawing parallels with industry history—confidence can lead to overlooking vital checks.  Just as NASA faced challenges due to rapid launches, companies risk similar pitfalls without due diligence.\n",
      "\n",
      "[00:31:39] David Wynn: Yes, we must prevent overconfidence in testing and deploy agile systems that acknowledge potential issues.\n",
      "\n",
      "[00:34:08] Justin Grammens: Many companies fail to employ chaos engineering, disregarding the value of stress-testing systems to ensure resilience.\n",
      "\n",
      "[00:34:24] David Wynn: Indeed! Chaos engineering forces an organization to consider the worst-case scenarios actively while addressing system performance expectations.\n",
      "\n",
      "[00:34:53] Justin Grammens: As we wrap up, what advice would you give someone entering the technology field?\n",
      "\n",
      "[00:35:04] David Wynn: My advice is to follow your interests. The niche topics you’re drawn to may lead to innovative ideas. You can find resources on almost anything today. Engage with communities, ask questions online, fail, and learn—it's all part of the process!\n",
      "\n",
      "[00:36:53] Justin Grammens: Great advice. Even older resources can provide valuable insights, as industries often evolve at a slower pace.\n",
      "\n",
      "[00:39:12] David Wynn: Exactly! It’s about finding that intersection of interests and skills.\n",
      "\n",
      "[00:40:00] Justin Grammens: How can people connect with you after this conversation?\n",
      "\n",
      "[00:40:21] David Wynn: LinkedIn is best for reaching me. I have a professional-looking blazer in my profile picture!\n",
      "\n",
      "[00:40:47] Justin Grammens: We'll have your LinkedIn page and the relevant links in our show notes. Is there anything else you'd like to share?\n",
      "\n",
      "[00:41:58] David Wynn: I want to leave everyone with a hopeful thought. Many of us feel overwhelmed by the speed of change, thinking we don’t matter. Remember, the giants we stand on had the same doubts. They created impactful things, and so can you.\n",
      "\n",
      "[00:42:45] Justin Grammens: Inspiring indeed, David! It’s been a pleasure having you on the show. We appreciate your time and insights. Wishing you the best at Edge Delta and your future endeavors.\n",
      "\n",
      "[00:42:49] AI Announcer: You've listened to another episode of the Conversations on Applied AI podcast. We hope you are eager to learn more about applying artificial intelligence and deep learning within your organization. You can visit us at [AppliedAI.mn](https://www.google.com/search?q=AppliedAI.mn) to keep up to date on our events and connect with our amazing community. Please don't hesitate to reach out to Justin at [AppliedAI.mn](https://www.google.com/search?q=AppliedAI.mn) if you are interested in participating in a future episode. Thank you for listening.\n"
     ]
    }
   ],
   "source": [
    "example_name = list(transcripts.keys())[0]\n",
    "revised = rewrite_transcript(transcripts[example_name])\n",
    "print(strip_quotes(revised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f750aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[00:00:00] David Wynn: The mental model I like to give people is imagine a guy in a bar overheard 10,000 hours of two people next to him talking about motorcycles. He has never seen, driven, heard, or felt one. When you ask him a question about motorcycles, he’ll probably give you the right answer. Occasionally, he might compliment how your torque smells. It's not his fault. He's just trying to piece together everything he could possibly know from what he's heard. He's not really thinking it through. I think that model is key for people to grasp. As a result, summarizing—where I'm trusting someone to come up with the important stuff I need to know—feels a bit suspicious to me. If we called it shortening, that’d be different. Summarizing, I’m a little wary of.\n",
       "\n",
       "[00:00:48] AI Announcer: Welcome to the Conversations on Applied AI podcast, where Justin Grammens and the team at Emerging Technologies North talk with experts in the fields of artificial intelligence and deep learning. In each episode, we cut through the hype and dive into how these technologies are being applied to real-world problems today. We hope you find this episode educational and applicable to your industry. Connect with us to learn more about our organization at [AppliedAI.mn](https://www.google.com/search?q=AppliedAI.mn). Enjoy.\n",
       "\n",
       "[00:01:19] Justin Grammens: Welcome, everyone, to the Conversations on Applied AI podcast. I'm your host, Justin Grammens, and our guest today is David Wynn. David is the Principal Solution Architect at EdgeDelta and an enthusiast for all things technology. \n",
       "\n",
       "With a career spanning 15 years, including a pivotal role at Google Cloud for Games, David has cultivated a deep understanding of technical sales, solution architecture, and the transformative power of cloud services in the gaming industry and beyond. His unique perspective challenges the overreliance on AI, advocating for a balanced approach that leverages human ingenuity alongside technological advancements, especially in areas like observability.\n",
       "\n",
       "When he's not steering innovation, David revels in the vibrant geek culture of Atlanta and is a regular at DragonCon, the largest multimedia popular culture convention focusing on science fiction and fantasy. His diverse interests span from technology to philosophy. I’m sure we’re going to have an awesome conversation today about AI and its applications. Thank you so much for being on the program.\n",
       "\n",
       "[00:02:11] David Wynn: Absolutely, Justin. Pleasure to be here.\n",
       "\n",
       "[00:02:13] Justin Grammens: Awesome. I touched on some of your background at Google and your current role. I'm curious, how did you get into technology? Were you always fascinated with programming?\n",
       "\n",
       "[00:02:31] David Wynn: I grew up in Greenville, South Carolina, which is not a technical hub in the U.S. My only teacher, Miss Harmon, was my computer science teacher throughout high school. That was just enough to spark my interest, but I went to college for economics instead. I had the wrong impression about what it meant to be a programmer, so I thought I’d do something else.\n",
       "\n",
       "After college, I ended up spending time at UPS during the 2008 crash, where a PhD and I worked on econometrics to improve forecasting. My role involved a lot of VBA code to make Excel work for 250 time series data sets, which is where I started developing practical skills. \n",
       "\n",
       "Later, I moved to California for a relationship, and at the Stanford career fair, I found a lot of technology opportunities. I ended up doing post-sales implementation middleware, which was a form of ETL. I built scalable data pipelines for law firms and transitioned into observability at Sumo Logic. Eventually, I joined Google Cloud when it was small, around 70 sales engineers globally, which was a rapid learning experience for cloud technologies. Now, I'm back in observability at Edge Delta.\n",
       "\n",
       "[00:05:42] Justin Grammens: Great journey! For our audience, could you define what observability is?\n",
       "\n",
       "[00:05:51] David Wynn: Depending on how good your Googling or using GPT is, observability can be defined simply as logs, metrics, and traces. Essentially, an application generates data about itself to show how well it's running. Collecting and displaying that information is observability.\n",
       "\n",
       "A broader way to define it is the process of ensuring that what you’re doing is operating as expected. This understanding goes beyond any specific metric, allowing for flexibility in approach. The observability space is transitioning because our data has become enormous, reaching hundreds of terabytes to petabytes generated daily.\n",
       "\n",
       "When running applications on multiple machines, observability software pulls all that data together to find what’s important. However, scalability has become an issue as the volume increases.\n",
       "\n",
       "[00:07:24] Justin Grammens: I've worked in the Internet of Things and sensors for over 15 years. At some point, processing becomes overwhelming, and I turned to machine learning and deep learning to filter through the noise. Can you discuss AI's role in observability?\n",
       "\n",
       "[00:07:54] David Wynn: There’s a group of people very hopeful about AI, believing that if we throw all our data into it, it will find solutions. On the other hand, we know that errors and crashes are bad, and we generally understand the data we have. For example, at Edge Delta, we use a traditional machine learning model to identify statistical abnormalities. Then, we feed this information into an LLM to suggest next actions to take.\n",
       "\n",
       "This is like having a 2 a.m. crib sheet for trouble-shooting—a quick list of things to check if something goes wrong. This process can be very useful for resolving issues and getting people back to bed, especially for those new to the team.\n",
       "\n",
       "[00:09:27] Justin Grammens: It's a practical application of generative AI, particularly for junior engineers on call. They need backup when systems fail at inconvenient times.\n",
       "\n",
       "[00:09:50] David Wynn: Exactly. When debugging, you may be isolating problems across teams and encountering new challenges. This complexity can vary greatly if there’s a lack of communication around team decision-making and implementation.\n",
       "\n",
       "[00:10:21] Justin Grammens: I've talked to engineers who have difficulty deciphering logs and hardware dumps. They're looking for anomaly detection to guide them when they aren't familiar with the code or libraries.\n",
       "\n",
       "[00:10:50] David Wynn: Different approaches exist to abstract problems. Some errors may require immediate resolution, while other conditions involve deeper awareness of a broader context. Higher-level issues may relate to architecture state or model performance.\n",
       "\n",
       "LLMs can help translate command logs into actionable insights, but they struggle with new or unprecedented problems. For instance, I encountered a unique billing error at Intap—a failure in our sync service due to an unpaid account. LLMs might not provide guidance on rare errors that haven’t been encountered before, but they excel in generating ideas and constructing outlines for broader queries.\n",
       "\n",
       "[00:13:55] Justin Grammens: I agree that LLMs lack intuition when it comes to errors. They're great for specific tasks, but they struggle with nuances and unique scenarios. And while they improve efficiency in mundane tasks, they're not perfect tools for summarizing or assessing the uniqueness of issues.\n",
       "\n",
       "[00:15:47] David Wynn: Absolutely. While they can help streamline processes, their ability to resolve complex problems is limited.\n",
       "\n",
       "[00:15:59] Justin Grammens: There’s concern around AI potentially replacing jobs. What’s your view on that?\n",
       "\n",
       "[00:16:01] David Wynn: I’m generally not worried. If you try to get these technologies to perform tasks you’re concerned about, you might find challenges. For example, creating sophisticated art with AI can often lead to frustrating results. People will always seek specificity and control, which can be lost with AI.\n",
       "\n",
       "My impression is that AI is not going to completely replace roles but will enhance processes, helping eliminate inefficient tasks. AI will streamline operations, allowing people to focus on higher-level problem-solving.\n",
       "\n",
       "[00:18:53] Justin Grammens: Makes sense. Current tools enhance capabilities rather than completely displace them. People will experience increased ROI with smart tools. \n",
       "\n",
       "[00:20:26] David Wynn: Exactly! Many current AI tools become more intelligent through user interaction, enhancing daily workflows.\n",
       "\n",
       "[00:20:40] Justin Grammens: While generative AI has captured imaginations, many startups will fade away amidst the hype. Existing products will adapt and integrate AI efficiently.\n",
       "\n",
       "[00:21:44] David Wynn: Agreed! Many companies are focusing on value-driven models rather than sheer size. Innovations will improve specific applications, creating more effective and targeted solutions.\n",
       "\n",
       "[00:22:59] Justin Grammens: Observability is key to identifying and fixing system issues, as we saw with CrowdStrike recently. It highlights the need for better testing and pre-release verification of system changes.\n",
       "\n",
       "[00:27:52] David Wynn: Absolutely! If a deployment has a large blast radius, precautions should have been taken to catch potential issues. Observability measures must be effective enough to predict problems before they occur.\n",
       "\n",
       "[00:30:50] Justin Grammens: Drawing parallels with industry history—confidence can lead to overlooking vital checks.  Just as NASA faced challenges due to rapid launches, companies risk similar pitfalls without due diligence.\n",
       "\n",
       "[00:31:39] David Wynn: Yes, we must prevent overconfidence in testing and deploy agile systems that acknowledge potential issues.\n",
       "\n",
       "[00:34:08] Justin Grammens: Many companies fail to employ chaos engineering, disregarding the value of stress-testing systems to ensure resilience.\n",
       "\n",
       "[00:34:24] David Wynn: Indeed! Chaos engineering forces an organization to consider the worst-case scenarios actively while addressing system performance expectations.\n",
       "\n",
       "[00:34:53] Justin Grammens: As we wrap up, what advice would you give someone entering the technology field?\n",
       "\n",
       "[00:35:04] David Wynn: My advice is to follow your interests. The niche topics you’re drawn to may lead to innovative ideas. You can find resources on almost anything today. Engage with communities, ask questions online, fail, and learn—it's all part of the process!\n",
       "\n",
       "[00:36:53] Justin Grammens: Great advice. Even older resources can provide valuable insights, as industries often evolve at a slower pace.\n",
       "\n",
       "[00:39:12] David Wynn: Exactly! It’s about finding that intersection of interests and skills.\n",
       "\n",
       "[00:40:00] Justin Grammens: How can people connect with you after this conversation?\n",
       "\n",
       "[00:40:21] David Wynn: LinkedIn is best for reaching me. I have a professional-looking blazer in my profile picture!\n",
       "\n",
       "[00:40:47] Justin Grammens: We'll have your LinkedIn page and the relevant links in our show notes. Is there anything else you'd like to share?\n",
       "\n",
       "[00:41:58] David Wynn: I want to leave everyone with a hopeful thought. Many of us feel overwhelmed by the speed of change, thinking we don’t matter. Remember, the giants we stand on had the same doubts. They created impactful things, and so can you.\n",
       "\n",
       "[00:42:45] Justin Grammens: Inspiring indeed, David! It’s been a pleasure having you on the show. We appreciate your time and insights. Wishing you the best at Edge Delta and your future endeavors.\n",
       "\n",
       "[00:42:49] AI Announcer: You've listened to another episode of the Conversations on Applied AI podcast. We hope you are eager to learn more about applying artificial intelligence and deep learning within your organization. You can visit us at [AppliedAI.mn](https://www.google.com/search?q=AppliedAI.mn) to keep up to date on our events and connect with our amazing community. Please don't hesitate to reach out to Justin at [AppliedAI.mn](https://www.google.com/search?q=AppliedAI.mn) if you are interested in participating in a future episode. Thank you for listening."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(strip_quotes(revised)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55180561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def convert_timestamps_to_links(text, base_url):\n",
    "    def replace_timestamp(match):\n",
    "        time_str = match.group(1)\n",
    "        parts = time_str.split(\":\")\n",
    "        if len(parts) == 3:  # hh:mm:ss\n",
    "            h, m, s = parts\n",
    "            total_seconds = int(h) * 3600 + int(m) * 60 + int(s)\n",
    "        elif len(parts) == 2:  # mm:ss\n",
    "            m, s = parts\n",
    "            total_seconds = int(m) * 60 + int(s)\n",
    "        else:  # fallback\n",
    "            total_seconds = int(parts[0])\n",
    "        return f\"[{time_str}]({base_url}?t={total_seconds})\"\n",
    "\n",
    "    pattern = r\"\\[([0-9]{1,2}:[0-9]{2}(?::[0-9]{2})?)\\]\"\n",
    "    return re.sub(pattern, replace_timestamp, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5636017f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[00:00:00](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=0) David Wynn: The mental model I like to give people is imagine a guy in a bar overheard 10,000 hours of two people next to him talking about motorcycles. He has never seen, driven, heard, or felt one. When you ask him a question about motorcycles, he’ll probably give you the right answer. Occasionally, he might compliment how your torque smells. It's not his fault. He's just trying to piece together everything he could possibly know from what he's heard. He's not really thinking it through. I think that model is key for people to grasp. As a result, summarizing—where I'm trusting someone to come up with the important stuff I need to know—feels a bit suspicious to me. If we called it shortening, that’d be different. Summarizing, I’m a little wary of.\n",
       "\n",
       "[00:00:48](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=48) AI Announcer: Welcome to the Conversations on Applied AI podcast, where Justin Grammens and the team at Emerging Technologies North talk with experts in the fields of artificial intelligence and deep learning. In each episode, we cut through the hype and dive into how these technologies are being applied to real-world problems today. We hope you find this episode educational and applicable to your industry. Connect with us to learn more about our organization at [AppliedAI.mn](https://www.google.com/search?q=AppliedAI.mn). Enjoy.\n",
       "\n",
       "[00:01:19](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=79) Justin Grammens: Welcome, everyone, to the Conversations on Applied AI podcast. I'm your host, Justin Grammens, and our guest today is David Wynn. David is the Principal Solution Architect at EdgeDelta and an enthusiast for all things technology. \n",
       "\n",
       "With a career spanning 15 years, including a pivotal role at Google Cloud for Games, David has cultivated a deep understanding of technical sales, solution architecture, and the transformative power of cloud services in the gaming industry and beyond. His unique perspective challenges the overreliance on AI, advocating for a balanced approach that leverages human ingenuity alongside technological advancements, especially in areas like observability.\n",
       "\n",
       "When he's not steering innovation, David revels in the vibrant geek culture of Atlanta and is a regular at DragonCon, the largest multimedia popular culture convention focusing on science fiction and fantasy. His diverse interests span from technology to philosophy. I’m sure we’re going to have an awesome conversation today about AI and its applications. Thank you so much for being on the program.\n",
       "\n",
       "[00:02:11](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=131) David Wynn: Absolutely, Justin. Pleasure to be here.\n",
       "\n",
       "[00:02:13](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=133) Justin Grammens: Awesome. I touched on some of your background at Google and your current role. I'm curious, how did you get into technology? Were you always fascinated with programming?\n",
       "\n",
       "[00:02:31](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=151) David Wynn: I grew up in Greenville, South Carolina, which is not a technical hub in the U.S. My only teacher, Miss Harmon, was my computer science teacher throughout high school. That was just enough to spark my interest, but I went to college for economics instead. I had the wrong impression about what it meant to be a programmer, so I thought I’d do something else.\n",
       "\n",
       "After college, I ended up spending time at UPS during the 2008 crash, where a PhD and I worked on econometrics to improve forecasting. My role involved a lot of VBA code to make Excel work for 250 time series data sets, which is where I started developing practical skills. \n",
       "\n",
       "Later, I moved to California for a relationship, and at the Stanford career fair, I found a lot of technology opportunities. I ended up doing post-sales implementation middleware, which was a form of ETL. I built scalable data pipelines for law firms and transitioned into observability at Sumo Logic. Eventually, I joined Google Cloud when it was small, around 70 sales engineers globally, which was a rapid learning experience for cloud technologies. Now, I'm back in observability at Edge Delta.\n",
       "\n",
       "[00:05:42](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=342) Justin Grammens: Great journey! For our audience, could you define what observability is?\n",
       "\n",
       "[00:05:51](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=351) David Wynn: Depending on how good your Googling or using GPT is, observability can be defined simply as logs, metrics, and traces. Essentially, an application generates data about itself to show how well it's running. Collecting and displaying that information is observability.\n",
       "\n",
       "A broader way to define it is the process of ensuring that what you’re doing is operating as expected. This understanding goes beyond any specific metric, allowing for flexibility in approach. The observability space is transitioning because our data has become enormous, reaching hundreds of terabytes to petabytes generated daily.\n",
       "\n",
       "When running applications on multiple machines, observability software pulls all that data together to find what’s important. However, scalability has become an issue as the volume increases.\n",
       "\n",
       "[00:07:24](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=444) Justin Grammens: I've worked in the Internet of Things and sensors for over 15 years. At some point, processing becomes overwhelming, and I turned to machine learning and deep learning to filter through the noise. Can you discuss AI's role in observability?\n",
       "\n",
       "[00:07:54](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=474) David Wynn: There’s a group of people very hopeful about AI, believing that if we throw all our data into it, it will find solutions. On the other hand, we know that errors and crashes are bad, and we generally understand the data we have. For example, at Edge Delta, we use a traditional machine learning model to identify statistical abnormalities. Then, we feed this information into an LLM to suggest next actions to take.\n",
       "\n",
       "This is like having a 2 a.m. crib sheet for trouble-shooting—a quick list of things to check if something goes wrong. This process can be very useful for resolving issues and getting people back to bed, especially for those new to the team.\n",
       "\n",
       "[00:09:27](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=567) Justin Grammens: It's a practical application of generative AI, particularly for junior engineers on call. They need backup when systems fail at inconvenient times.\n",
       "\n",
       "[00:09:50](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=590) David Wynn: Exactly. When debugging, you may be isolating problems across teams and encountering new challenges. This complexity can vary greatly if there’s a lack of communication around team decision-making and implementation.\n",
       "\n",
       "[00:10:21](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=621) Justin Grammens: I've talked to engineers who have difficulty deciphering logs and hardware dumps. They're looking for anomaly detection to guide them when they aren't familiar with the code or libraries.\n",
       "\n",
       "[00:10:50](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=650) David Wynn: Different approaches exist to abstract problems. Some errors may require immediate resolution, while other conditions involve deeper awareness of a broader context. Higher-level issues may relate to architecture state or model performance.\n",
       "\n",
       "LLMs can help translate command logs into actionable insights, but they struggle with new or unprecedented problems. For instance, I encountered a unique billing error at Intap—a failure in our sync service due to an unpaid account. LLMs might not provide guidance on rare errors that haven’t been encountered before, but they excel in generating ideas and constructing outlines for broader queries.\n",
       "\n",
       "[00:13:55](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=835) Justin Grammens: I agree that LLMs lack intuition when it comes to errors. They're great for specific tasks, but they struggle with nuances and unique scenarios. And while they improve efficiency in mundane tasks, they're not perfect tools for summarizing or assessing the uniqueness of issues.\n",
       "\n",
       "[00:15:47](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=947) David Wynn: Absolutely. While they can help streamline processes, their ability to resolve complex problems is limited.\n",
       "\n",
       "[00:15:59](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=959) Justin Grammens: There’s concern around AI potentially replacing jobs. What’s your view on that?\n",
       "\n",
       "[00:16:01](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=961) David Wynn: I’m generally not worried. If you try to get these technologies to perform tasks you’re concerned about, you might find challenges. For example, creating sophisticated art with AI can often lead to frustrating results. People will always seek specificity and control, which can be lost with AI.\n",
       "\n",
       "My impression is that AI is not going to completely replace roles but will enhance processes, helping eliminate inefficient tasks. AI will streamline operations, allowing people to focus on higher-level problem-solving.\n",
       "\n",
       "[00:18:53](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=1133) Justin Grammens: Makes sense. Current tools enhance capabilities rather than completely displace them. People will experience increased ROI with smart tools. \n",
       "\n",
       "[00:20:26](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=1226) David Wynn: Exactly! Many current AI tools become more intelligent through user interaction, enhancing daily workflows.\n",
       "\n",
       "[00:20:40](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=1240) Justin Grammens: While generative AI has captured imaginations, many startups will fade away amidst the hype. Existing products will adapt and integrate AI efficiently.\n",
       "\n",
       "[00:21:44](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=1304) David Wynn: Agreed! Many companies are focusing on value-driven models rather than sheer size. Innovations will improve specific applications, creating more effective and targeted solutions.\n",
       "\n",
       "[00:22:59](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=1379) Justin Grammens: Observability is key to identifying and fixing system issues, as we saw with CrowdStrike recently. It highlights the need for better testing and pre-release verification of system changes.\n",
       "\n",
       "[00:27:52](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=1672) David Wynn: Absolutely! If a deployment has a large blast radius, precautions should have been taken to catch potential issues. Observability measures must be effective enough to predict problems before they occur.\n",
       "\n",
       "[00:30:50](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=1850) Justin Grammens: Drawing parallels with industry history—confidence can lead to overlooking vital checks.  Just as NASA faced challenges due to rapid launches, companies risk similar pitfalls without due diligence.\n",
       "\n",
       "[00:31:39](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=1899) David Wynn: Yes, we must prevent overconfidence in testing and deploy agile systems that acknowledge potential issues.\n",
       "\n",
       "[00:34:08](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=2048) Justin Grammens: Many companies fail to employ chaos engineering, disregarding the value of stress-testing systems to ensure resilience.\n",
       "\n",
       "[00:34:24](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=2064) David Wynn: Indeed! Chaos engineering forces an organization to consider the worst-case scenarios actively while addressing system performance expectations.\n",
       "\n",
       "[00:34:53](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=2093) Justin Grammens: As we wrap up, what advice would you give someone entering the technology field?\n",
       "\n",
       "[00:35:04](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=2104) David Wynn: My advice is to follow your interests. The niche topics you’re drawn to may lead to innovative ideas. You can find resources on almost anything today. Engage with communities, ask questions online, fail, and learn—it's all part of the process!\n",
       "\n",
       "[00:36:53](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=2213) Justin Grammens: Great advice. Even older resources can provide valuable insights, as industries often evolve at a slower pace.\n",
       "\n",
       "[00:39:12](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=2352) David Wynn: Exactly! It’s about finding that intersection of interests and skills.\n",
       "\n",
       "[00:40:00](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=2400) Justin Grammens: How can people connect with you after this conversation?\n",
       "\n",
       "[00:40:21](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=2421) David Wynn: LinkedIn is best for reaching me. I have a professional-looking blazer in my profile picture!\n",
       "\n",
       "[00:40:47](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=2447) Justin Grammens: We'll have your LinkedIn page and the relevant links in our show notes. Is there anything else you'd like to share?\n",
       "\n",
       "[00:41:58](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=2518) David Wynn: I want to leave everyone with a hopeful thought. Many of us feel overwhelmed by the speed of change, thinking we don’t matter. Remember, the giants we stand on had the same doubts. They created impactful things, and so can you.\n",
       "\n",
       "[00:42:45](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=2565) Justin Grammens: Inspiring indeed, David! It’s been a pleasure having you on the show. We appreciate your time and insights. Wishing you the best at Edge Delta and your future endeavors.\n",
       "\n",
       "[00:42:49](https://appliedai.buzzsprout.com/1101152/episodes/16272078-david-wynn-striking-the-balance-between-ai-summarizing-and-human-insight?t=2569) AI Announcer: You've listened to another episode of the Conversations on Applied AI podcast. We hope you are eager to learn more about applying artificial intelligence and deep learning within your organization. You can visit us at [AppliedAI.mn](https://www.google.com/search?q=AppliedAI.mn) to keep up to date on our events and connect with our amazing community. Please don't hesitate to reach out to Justin at [AppliedAI.mn](https://www.google.com/search?q=AppliedAI.mn) if you are interested in participating in a future episode. Thank you for listening."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "linked_markdown = convert_timestamps_to_links(strip_quotes(revised), links[example_name])\n",
    "display(Markdown(linked_markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57cd9b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outline_prompt = \"\"\"\n",
    "Below is an example **prompt** you can give to an LLM. It walks the model through **(1)** examining the nature of the podcast, **(2)** generating an outline in a code block, and **(3)** rewriting the transcript with named-anchor headings that match the outline. Be sure to replace any placeholders (like `<<FULL TRANSCRIPT HERE>>`) with the actual transcript text.\n",
    "\n",
    "---\n",
    "\n",
    "## Prompt for the LLM\n",
    "\n",
    "You are given a podcast transcript and some instructions. Please follow these steps:\n",
    "\n",
    "1. **Analyze the Nature of the Podcast**\n",
    "   - Read through the entire transcript to understand its main themes, flow, and the natural breaks (such as introductions, key topics, speaker transitions, wrap-up).\n",
    "\n",
    "2. **Create an Outline**\n",
    "   - Summarize the podcast’s structure as an outline.\n",
    "   - Use a code fence labeled `outline` to present this outline.\n",
    "   - Each major section in the outline should reflect logical segments of the conversation (e.g., “Introduction,” “Guest Background,” “Core Discussion,” “Future Outlook,” “Conclusion,” etc.).\n",
    "   - Example of how to structure it:\n",
    "     ```outline\n",
    "     1. Introduction\n",
    "       a. AI Voice Intro\n",
    "       b. Host’s Welcome\n",
    "     2. Guest Background\n",
    "       ...\n",
    "     ```\n",
    "\n",
    "3. **Rewrite the Transcript with Headings**\n",
    "   - Insert headings in the cleaned-up version of the transcript corresponding to each section of the outline.\n",
    "   - For each heading, use **named anchors** with the format:\n",
    "     ```\n",
    "     # <span id=\"section-name\">Section Title</span>\n",
    "     ```\n",
    "   - Wherever a reference to that section might appear in the text (like a table of contents or references), link to it using:\n",
    "     ```\n",
    "     [Section Title](#section-name)\n",
    "     ```\n",
    "   - Use a number of #'s to indicate the heading level, copying the structure of the outline.\n",
    "\n",
    "4. **Return the Output in Two Parts**\n",
    "   1. The **Outline** in a fenced code block labeled `outline`.\n",
    "   2. The **Rewritten Transcript** with headings using named anchors.\n",
    "\n",
    "5. **Use This Transcript**\n",
    "   **Transcript (raw):**\n",
    "   ```\n",
    "   <<FULL TRANSCRIPT HERE>>\n",
    "   ```\n",
    "\n",
    "### Example Illustrations of Format\n",
    "\n",
    "- **Outline Code Block**:\n",
    "  ```outline\n",
    "  1. [Introduction](#introduction)\n",
    "    a. [Podcast overview](#podcast-overview)\n",
    "    b. [Introduction of guest](#introduction-of-guest)\n",
    "  2. [Key Discussion](#key-discussion)\n",
    "    a. [Early career](#early-career)\n",
    "    b. [Tech adoption](#tech-adoption)\n",
    "  3. [Conclusion](#conclusion)\n",
    "    a. [Final thoughts](#final-thoughts)\n",
    "    b. [Outro](#outro)\n",
    "  ```\n",
    "\n",
    "- **Named Anchor Headings** in the rewritten transcript:\n",
    "  ```transcript\n",
    "  # <span id=\"introduction\">Introduction</span>\n",
    "\n",
    "  [00:00] Host: Welcome to the show! ...\n",
    "\n",
    "  # <span id=\"key-discussion\">Key Discussion</span>\n",
    "\n",
    "  [00:05] Guest: So let's dive in ...\n",
    "  ```\n",
    "\n",
    "### Final Instructions\n",
    "\n",
    "1. **Don’t insert extra commentary** in the final output—just produce the outline and the rewritten transcript.\n",
    "2. Include ```outline ...``` and ```transcript ...``` code fences in your response.\n",
    "3. Return your final answer as **valid Markdown**.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9527218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outline_transcript(text):\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": outline_prompt},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ]\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "def extract_code_blocks(text: str):\n",
    "    pattern = re.compile(r'```([^\\n]+)\\n([\\s\\S]*?)```')\n",
    "    blocks = []\n",
    "    for tag, content in pattern.findall(text):\n",
    "        blocks.append({\"tag\": tag.strip(), \"content\": content.strip()})\n",
    "    return blocks\n",
    "\n",
    "def extract_outline_and_transcript(text):\n",
    "    blocks = extract_code_blocks(text)\n",
    "    return \"\\n\\n\".join([block[\"content\"] for block in blocks])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09b317f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. [Introduction](#introduction)\n",
       "   a. [Opening Remarks](#opening-remarks)\n",
       "   b. [Guest Introduction](#guest-introduction)\n",
       "2. [David Wynn's Background](#david-wynns-background)\n",
       "   a. [Early Life and Career](#early-life-and-career)\n",
       "   b. [Transition into Technology](#transition-into-technology)\n",
       "3. [Understanding Observability](#understanding-observability)\n",
       "   a. [Definition and Importance](#definition-and-importance)\n",
       "   b. [AI's Role in Observability](#ais-role-in-observability)\n",
       "4. [Challenges with AI](#challenges-with-ai)\n",
       "   a. [Limitations of Large Language Models](#limitations-of-large-language-models)\n",
       "   b. [AI's Impact on Jobs](#ais-impact-on-jobs)\n",
       "5. [Best Practices in Technology](#best-practices-in-technology)\n",
       "   a. [Advice for Newcomers](#advice-for-newcomers)\n",
       "   b. [Importance of Community Engagement](#importance-of-community-engagement)\n",
       "6. [Closing Thoughts and Insights](#closing-thoughts-and-insights)\n",
       "   a. [Personal Reflections](#personal-reflections)\n",
       "   b. [Conclusion](#conclusion)\n",
       "\n",
       "# <span id=\"introduction\">Introduction</span>\n",
       "\n",
       "[00:00:00] David Wynn: The mental model I like to give people is imagine a guy in a bar overheard 10,000 hours of two people next to him talking about motorcycles. He has never seen, driven, heard, or felt one. When you ask him a question about motorcycles, he’ll probably give you the right answer. Occasionally, he might compliment how your torque smells. It's not his fault. He's just trying to piece together everything he could possibly know from what he's heard. He's not really thinking it through. I think that model is key for people to grasp. As a result, summarizing—where I'm trusting someone to come up with the important stuff I need to know—feels a bit suspicious to me. If we called it shortening, that’d be different. Summarizing, I’m a little wary of.\n",
       "\n",
       "[00:00:48] AI Announcer: Welcome to the Conversations on Applied AI podcast, where Justin Grammens and the team at Emerging Technologies North talk with experts in the fields of artificial intelligence and deep learning. In each episode, we cut through the hype and dive into how these technologies are being applied to real-world problems today. We hope you find this episode educational and applicable to your industry. Connect with us to learn more about our organization at [AppliedAI.mn](https://www.google.com/search?q=AppliedAI.mn). Enjoy.\n",
       "\n",
       "# <span id=\"opening-remarks\">Opening Remarks</span>\n",
       "\n",
       "[00:01:19] Justin Grammens: Welcome, everyone, to the Conversations on Applied AI podcast. I'm your host, Justin Grammens, and our guest today is David Wynn. David is the Principal Solution Architect at EdgeDelta and an enthusiast for all things technology. \n",
       "\n",
       "With a career spanning 15 years, including a pivotal role at Google Cloud for Games, David has cultivated a deep understanding of technical sales, solution architecture, and the transformative power of cloud services in the gaming industry and beyond. His unique perspective challenges the overreliance on AI, advocating for a balanced approach that leverages human ingenuity alongside technological advancements, especially in areas like observability.\n",
       "\n",
       "When he's not steering innovation, David revels in the vibrant geek culture of Atlanta and is a regular at DragonCon, the largest multimedia popular culture convention focusing on science fiction and fantasy. His diverse interests span from technology to philosophy. I’m sure we’re going to have an awesome conversation today about AI and its applications. Thank you so much for being on the program.\n",
       "\n",
       "# <span id=\"guest-introduction\">Guest Introduction</span>\n",
       "\n",
       "[00:02:11] David Wynn: Absolutely, Justin. Pleasure to be here.\n",
       "\n",
       "# <span id=\"david-wynns-background\">David Wynn's Background</span>\n",
       "\n",
       "# <span id=\"early-life-and-career\">Early Life and Career</span>\n",
       "\n",
       "[00:02:13] Justin Grammens: Awesome. I touched on some of your background at Google and your current role. I'm curious, how did you get into technology? Were you always fascinated with programming?\n",
       "\n",
       "[00:02:31] David Wynn: I grew up in Greenville, South Carolina, which is not a technical hub in the U.S. My only teacher, Miss Harmon, was my computer science teacher throughout high school. That was just enough to spark my interest, but I went to college for economics instead. I had the wrong impression about what it meant to be a programmer, so I thought I’d do something else.\n",
       "\n",
       "After college, I ended up spending time at UPS during the 2008 crash, where a PhD and I worked on econometrics to improve forecasting. My role involved a lot of VBA code to make Excel work for 250 time series data sets, which is where I started developing practical skills.\n",
       "\n",
       "# <span id=\"transition-into-technology\">Transition into Technology</span>\n",
       "\n",
       "Later, I moved to California for a relationship, and at the Stanford career fair, I found a lot of technology opportunities. I ended up doing post-sales implementation middleware, which was a form of ETL. I built scalable data pipelines for law firms and transitioned into observability at Sumo Logic. Eventually, I joined Google Cloud when it was small, around 70 sales engineers globally, which was a rapid learning experience for cloud technologies. Now, I'm back in observability at Edge Delta.\n",
       "\n",
       "# <span id=\"understanding-observability\">Understanding Observability</span>\n",
       "\n",
       "# <span id=\"definition-and-importance\">Definition and Importance</span>\n",
       "\n",
       "[00:05:42] Justin Grammens: Great journey! For our audience, could you define what observability is?\n",
       "\n",
       "[00:05:51] David Wynn: Depending on how good your Googling or using GPT is, observability can be defined simply as logs, metrics, and traces. Essentially, an application generates data about itself to show how well it's running. Collecting and displaying that information is observability.\n",
       "\n",
       "A broader way to define it is the process of ensuring that what you’re doing is operating as expected. This understanding goes beyond any specific metric, allowing for flexibility in approach. The observability space is transitioning because our data has become enormous, reaching hundreds of terabytes to petabytes generated daily.\n",
       "\n",
       "When running applications on multiple machines, observability software pulls all that data together to find what’s important. However, scalability has become an issue as the volume increases.\n",
       "\n",
       "# <span id=\"ais-role-in-observability\">AI's Role in Observability</span>\n",
       "\n",
       "[00:07:24] Justin Grammens: I've worked in the Internet of Things and sensors for over 15 years. At some point, processing becomes overwhelming, and I turned to machine learning and deep learning to filter through the noise. Can you discuss AI's role in observability?\n",
       "\n",
       "[00:07:54] David Wynn: There’s a group of people very hopeful about AI, believing that if we throw all our data into it, it will find solutions. On the other hand, we know that errors and crashes are bad, and we generally understand the data we have. For example, at Edge Delta, we use a traditional machine learning model to identify statistical abnormalities. Then, we feed this information into an LLM to suggest next actions to take.\n",
       "\n",
       "This is like having a 2 a.m. crib sheet for trouble-shooting—a quick list of things to check if something goes wrong. This process can be very useful for resolving issues and getting people back to bed, especially for those new to the team.\n",
       "\n",
       "# <span id=\"challenges-with-ai\">Challenges with AI</span>\n",
       "\n",
       "# <span id=\"limitations-of-large-language-models\">Limitations of Large Language Models</span>\n",
       "\n",
       "[00:09:27] Justin Grammens: It's a practical application of generative AI, particularly for junior engineers on call. They need backup when systems fail at inconvenient times.\n",
       "\n",
       "[00:09:50] David Wynn: Exactly. When debugging, you may be isolating problems across teams and encountering new challenges. This complexity can vary greatly if there’s a lack of communication around team decision-making and implementation.\n",
       "\n",
       "[00:10:21] Justin Grammens: I've talked to engineers who have difficulty deciphering logs and hardware dumps. They're looking for anomaly detection to guide them when they aren't familiar with the code or libraries.\n",
       "\n",
       "[00:10:50] David Wynn: Different approaches exist to abstract problems. Some errors may require immediate resolution, while other conditions involve deeper awareness of a broader context. Higher-level issues may relate to architecture state or model performance.\n",
       "\n",
       "LLMs can help translate command logs into actionable insights, but they struggle with new or unprecedented problems. For instance, I encountered a unique billing error at Intap—a failure in our sync service due to an unpaid account. LLMs might not provide guidance on rare errors that haven’t been encountered before, but they excel in generating ideas and constructing outlines for broader queries.\n",
       "\n",
       "# <span id=\"ais-impact-on-jobs\">AI's Impact on Jobs</span>\n",
       "\n",
       "[00:13:55] Justin Grammens: I agree that LLMs lack intuition when it comes to errors. They're great for specific tasks, but they struggle with nuances and unique scenarios. And while they improve efficiency in mundane tasks, they're not perfect tools for summarizing or assessing the uniqueness of issues.\n",
       "\n",
       "[00:15:47] David Wynn: Absolutely. While they can help streamline processes, their ability to resolve complex problems is limited.\n",
       "\n",
       "[00:15:59] Justin Grammens: There’s concern around AI potentially replacing jobs. What’s your view on that?\n",
       "\n",
       "[00:16:01] David Wynn: I’m generally not worried. If you try to get these technologies to perform tasks you’re concerned about, you might find challenges. For example, creating sophisticated art with AI can often lead to frustrating results. People will always seek specificity and control, which can be lost with AI.\n",
       "\n",
       "My impression is that AI is not going to completely replace roles but will enhance processes, helping eliminate inefficient tasks. AI will streamline operations, allowing people to focus on higher-level problem-solving.\n",
       "\n",
       "# <span id=\"best-practices-in-technology\">Best Practices in Technology</span>\n",
       "\n",
       "# <span id=\"advice-for-newcomers\">Advice for Newcomers</span>\n",
       "\n",
       "[00:18:53] Justin Grammens: Makes sense. Current tools enhance capabilities rather than completely displace them. People will experience increased ROI with smart tools. \n",
       "\n",
       "[00:20:26] David Wynn: Exactly! Many current AI tools become more intelligent through user interaction, enhancing daily workflows.\n",
       "\n",
       "[00:20:40] Justin Grammens: While generative AI has captured imaginations, many startups will fade away amidst the hype. Existing products will adapt and integrate AI efficiently.\n",
       "\n",
       "[00:21:44] David Wynn: Agreed! Many companies are focusing on value-driven models rather than sheer size. Innovations will improve specific applications, creating more effective and targeted solutions.\n",
       "\n",
       "# <span id=\"importance-of-community-engagement\">Importance of Community Engagement</span>\n",
       "\n",
       "[00:22:59] Justin Grammens: Observability is key to identifying and fixing system issues, as we saw with CrowdStrike recently. It highlights the need for better testing and pre-release verification of system changes.\n",
       "\n",
       "[00:27:52] David Wynn: Absolutely! If a deployment has a large blast radius, precautions should have been taken to catch potential issues. Observability measures must be effective enough to predict problems before they occur.\n",
       "\n",
       "[00:30:50] Justin Grammens: Drawing parallels with industry history—confidence can lead to overlooking vital checks. Just as NASA faced challenges due to rapid launches, companies risk similar pitfalls without due diligence.\n",
       "\n",
       "[00:31:39] David Wynn: Yes, we must prevent overconfidence in testing and deploy agile systems that acknowledge potential issues.\n",
       "\n",
       "[00:34:08] Justin Grammens: Many companies fail to employ chaos engineering, disregarding the value of stress-testing systems to ensure resilience.\n",
       "\n",
       "[00:34:24] David Wynn: Indeed! Chaos engineering forces an organization to consider the worst-case scenarios actively while addressing system performance expectations.\n",
       "\n",
       "# <span id=\"closing-thoughts-and-insights\">Closing Thoughts and Insights</span>\n",
       "\n",
       "# <span id=\"personal-reflections\">Personal Reflections</span>\n",
       "\n",
       "[00:34:53] Justin Grammens: As we wrap up, what advice would you give someone entering the technology field?\n",
       "\n",
       "[00:35:04] David Wynn: My advice is to follow your interests. The niche topics you’re drawn to may lead to innovative ideas. You can find resources on almost anything today. Engage with communities, ask questions online, fail, and learn—it’s all part of the process!\n",
       "\n",
       "[00:36:53] Justin Grammens: Great advice. Even older resources can provide valuable insights, as industries often evolve at a slower pace.\n",
       "\n",
       "[00:39:12] David Wynn: Exactly! It’s about finding that intersection of interests and skills.\n",
       "\n",
       "# <span id=\"conclusion\">Conclusion</span>\n",
       "\n",
       "[00:40:00] Justin Grammens: How can people connect with you after this conversation?\n",
       "\n",
       "[00:40:21] David Wynn: LinkedIn is best for reaching me. I have a professional-looking blazer in my profile picture!\n",
       "\n",
       "[00:40:47] Justin Grammens: We'll have your LinkedIn page and the relevant links in our show notes. Is there anything else you'd like to share?\n",
       "\n",
       "[00:41:58] David Wynn: I want to leave everyone with a hopeful thought. Many of us feel overwhelmed by the speed of change, thinking we don’t matter. Remember, the giants we stand on had the same doubts. They created impactful things, and so can you.\n",
       "\n",
       "[00:42:45] Justin Grammens: Inspiring indeed, David! It’s been a pleasure having you on the show. We appreciate your time and insights. Wishing you the best at Edge Delta and your future endeavors.\n",
       "\n",
       "[00:42:49] AI Announcer: You've listened to another episode of the Conversations on Applied AI podcast. We hope you are eager to learn more about applying artificial intelligence and deep learning within your organization. You can visit us at [AppliedAI.mn](https://www.google.com/search?q=AppliedAI.mn) to keep up to date on our events and connect with our amazing community. Please don't hesitate to reach out to Justin at [AppliedAI.mn](https://www.google.com/search?q=AppliedAI.mn) if you are interested in participating in a future episode. Thank you for listening."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outlined_transcript = outline_transcript(linked_markdown)\n",
    "formatted_outline = extract_outline_and_transcript(outlined_transcript)\n",
    "\n",
    "display(Markdown(formatted_outline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d96839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
